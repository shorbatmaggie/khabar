name: Run Google Alerts Scraper (manual + daily 11:35 UTC)

on:
  workflow_dispatch: {}   # manual trigger 
  schedule:
    - cron: "35 11 * * *"   # every day at 11:35 UTC (6:35 AM EST, 7:35 AM EDT)

concurrency:
  group: run-google-alerts
  cancel-in-progress: false

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: "requirements/google_scraper.txt"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements/google_scraper.txt

      - name: Ensure output directories
        run: |
          mkdir -p data/digests/google_digests
          mkdir -p data/error_logs/google_errors

      - name: Run scraper
        run: |
          python news_google_scraper.py

      - name: Upload artifacts (digests + error logs)
        uses: actions/upload-artifact@v4
        with:
          name: google-alerts-output-${{ github.run_id }}
          path: |
            data/digests/google_digests/*.csv
            data/error_logs/google_errors/*.csv
          if-no-files-found: warn
          retention-days: 30
